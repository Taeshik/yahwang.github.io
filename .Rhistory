table_output <- table(output)
data <- sort(table_output, decreasing = T)
class(data)
data_w <- data[1:100]
data_w
letterCloud(data_w, "청년")
data_w <- data[1:150]
letterCloud(data_w, "청년")
letterCloud(data_w, "청년", wordSize=2)
letterCloud(data_w, "청년", wordSize=5)
letterCloud(data_w, "청년", wordSize=5)
data_w <- data[1:50]
letterCloud(data_w, "청년", wordSize=5)
letterCloud(data_w, "청년", wordSize=5)
data_w
letterCloud(data_w, "청년", wordSize=10)
data_w <- data[1:300]
letterCloud(data_w, "청년", wordSize=5)
letterCloud(data_w, "청년", wordSize=5)
letterCloud(data_w, "청년", wordSize=0)
letterCloud(data_w, "청년", wordSize=0)
data_w <- data[1:200]
letterCloud(data_w, "청년", size=3)
letterCloud(data_w, "청년", size=2)
letterCloud(data_w, "A", size=2)
letterCloud(data_w, "A")
letterCloud(data_w, "A", wordSize = 2)
letterCloud(data_w, "A", wordSize = 0.5)
letterCloud(data_w, "A", wordSize = 0.5)
letterCloud(data_w, "A")
letterCloud(data_w, "R", letterFont = 'D2Coding')
letterCloud(data_w, "R", letterFont = 'Spoqa Han Sans')
data_w <- data[1:100]
letterCloud(data_w, "R", letterFont = 'Spoqa Han Sans')
data_w <- data[1:50]
letterCloud(data_w, "R")
data_w <- data[1:100]
letterCloud(data_w, "R")
data <- sort(table_output, decreasing = T)
wordcloud2(data_w, size=1.5)
wordcloud2(data_w)
wordcloud2(data_w,figPath = 'korea.png')
wordcloud2(data_w,figPath = 'korea.png')
data_w <- data[1:50]
wordcloud2(data_w,figPath = 'korea.png')
data_w <- data[1:30]
wordcloud2(data_w,figPath = 'korea.png')
wordcloud2(data_w,shuffle=F, figPath = 'korea.png')
data_w <- data[1:100]
data_w
wordcloud2(data_w,shuffle=F, figPath = 'korea.png')
wordcloud2(data_w,shuffle=F, figPath = 'korea.png')
wordcloud2(data_w,shuffle=F, minSize = 1, figPath = 'korea.png')
wordcloud2(data_w,shuffle=F, ellipticity = 0.2, figPath = 'korea.png')
wordcloud2(data_w,shuffle=F, ellipticity = 1, figPath = 'korea.png')
wordcloud2(data_w)
wordcloud2(data_w, shuffle=F, figPath = 'korea.png', widgetsize = 5)
wordcloud2(data_w, shuffle=F, figPath = 'korea.png', widgetsize = 100)
wordcloud2(data_w, shuffle=F, figPath = 'korea.png', widgetsize = 5)
a <- wordcloud2(data_w, figPath = 'korea.png')
wordcloud2Output(a,width = "500px", height = "500px")
wordcloud2Output(a,width = 100%, height = "500px")
wordcloud2Output(a, width = 100%, height = "500px")
a <- wordcloud2(data_w, figPath = 'korea.png', fontFamily = 'D2Coding')
a
View(data_w)
data_w['청년']
rm(data_w['청년'])
data_w[!'청년']
data_w[!청년]
data_w[!3]
data_w
data_w[3]
data_w[!3]
t <- data_w[!3]
t
t <- data_w[-'청년']
t <- data_w[-3]
t
t <- data_w[-c('청년')]
t <- data_w[-c('청년')]
t
data_w <- data[1:100]
t <- data_w[-c('청년')]
names(a) %in% c('청년')
names(data_w) %in% c('청년')
data_w[-names(data_w) %in% c('청년')]
data_w[-(names(data_w) %in% c('청년'))]
data_w <- data[1:100]
data_w[-(names(data_w) %in% c('청년'))]
data_w[!(names(data_w) %in% c('청년'))]
data_w[-1]
data_w[-2]
data_w['일자리']
data_w['일자리'] <- 6000
data_w
wordcloud2(data_w)
a <- wordcloud2(data_w, figPath = 'korea.png', fontFamily = 'D2Coding')
a <- wordcloud2(data_w, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, figPath = 'korea.png', fontFamily = 'D2Coding')
a <- c(1,2,3,4,5)
a[1:3]
a[1:3] <- a[1:3]+1
a
data_w[1:4]
data_w[1:4] <- data_w[1:4]-800
data_w
wordcloud2(data_w, figPath = 'korea.png', fontFamily = 'D2Coding')
data_w
wordcloud2(data_w)
wordcloud2(data_w, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, shuttle=F, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, shuffle=F, figPath = 'korea.png', fontFamily = 'D2Coding')
data_w <- data[1:50]
wordcloud2(data_w, shuffle=F, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, figPath = 'korea.png', fontFamily = 'D2Coding')
data_w <- data[1:30]
wordcloud2(data_w, figPath = 'korea.png', fontFamily = 'D2Coding')
data_w <- data[1:50]
data_w['일자리'] <- 5000
data_w[1:4] <- data_w[1:4]-800
data_w
wordcloud2(data_w, figPath = 'korea.png', fontFamily = 'D2Coding')
data_w
wordcloud2(data_w, figPath = 'korea.png', fontFamily = 'D2Coding')
data_w <- data[1:50]
data_w <- data_w / 100
data_w
wordcloud2(data_w, figPath = 'korea.png', fontFamily = 'D2Coding')
data_w[1] <- 60.2
wordcloud2(data_w, figPath = 'korea.png', fontFamily = 'D2Coding')
data_w
wordcloud2(data_w, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, shuffle=F, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.5, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.3, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.45, figPath = 'korea.png', fontFamily = 'D2Coding')
data_w <- data[1:50]
wordcloud2(data_w, size=0.45, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.5, figPath = 'korea.png', fontFamily = 'D2Coding')
data_w <- data[1:100]
wordcloud2(data_w, size=0.5, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.4, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.45, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.6, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.5, figPath = 'korea.png', fontFamily = 'D2Coding')
data_w <- data[1:50]
wordcloud2(data_w, size=0.5, figPath = 'korea.png', fontFamily = 'D2Coding')
data_w <- data[1:60]
wordcloud2(data_w, size=0.5, figPath = 'korea.png', fontFamily = 'D2Coding')
data_w <- data[1:50]
data_w <- data_w / 100
wordcloud2(data_w, size=0.5, figPath = 'korea.png', fontFamily = 'D2Coding')
data_w
data_w[1:4] <- data_w[1:4]-10
wordcloud2(data_w, size=0.5, figPath = 'korea.png', fontFamily = 'D2Coding')
data_w
data_w[1] <- data_w[1]-30
data_W
data_w
wordcloud2(data_w, size=0.5, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.4, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.45, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.45, gridSize=1,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.45, gridSize=2,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.45, gridSize=5,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.45, gridSize=0,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.45, gridSize=10,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.45, gridSize=50,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.45, gridSize=20,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.45, gridSize=10,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.45, gridSize=15,figPath = 'korea.png', fontFamily = 'D2Coding')
data_w <- data[1:100]
wordcloud2(data_w, size=0.45, gridSize=15,figPath = 'korea.png', fontFamily = 'D2Coding')
data_w
data_w <- data[1:50]
wordcloud2(data_w, size=0.45, gridSize=15,figPath = 'korea.png', fontFamily = 'D2Coding')
data_w[:]
data_w[:-1]
data_w2 <- data_w
data_w2
data_w2 <- 50:1
data_w2
data_w[1:length(data_w)] <- 50:1
data_w
wordcloud2(data_w, size=0.45, gridSize=15,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data_w, size=0.45, gridSize=5,figPath = 'korea.png', fontFamily = 'D2Coding')
data_w[1:length(data_w)] <-
seq(1,100,by=10)
data_w
data_w[1:length(data_w)] <- seq(100,1,by=10)
data_w[1:length(data_w)] <- seq(100,1,by=-10)
seq(100,10,by=-1)
seq(100,10,by=-10)
seq(100,1,by=-10)
data_w[1:length(data_w)] <- seq(250,1,by=-5)
data_w
wordcloud2(data_w, size=0.45, gridSize=5,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data[1:50])
wordcloud2(data_w, size=0.45, gridSize=5,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data[1:50]/200, size=0.45, gridSize=5,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2
wordcloud2(data[1:180]/200, size=0.45, gridSize=5,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data[1:180]/200, size=0.6, gridSize=10,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data[1:180]/200, size=0.4, gridSize=7,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data[1:180]/200, size=0.4, gridSize=20,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(data[1:50])
wordcloud2(data[1:100])
length(keywords)
keywords[2]
keywords[1]
length(keywords[1])
length(keywords[1][1])
length(keywords[1])
keywords[1]
length(keywords[1])
nrow(keywords[1])
class(keywords[1])
lengths(keywords[1])
lengths(keywords[1])
keywords[1][1]
keywords[1][2]
keywords[2]
length(output)
output <- character()
for ( i in 1:length(keywords)){
output <- c(output,str_split(keywords[i],',',simplify = F))
}
str(output)
output[[1]]
length(output)
for( i in 1:length(output)){
output[[i]] <- unique(output[[i]])
}
words <- unlist(output)
length(words)
news
library(tm)
install.packages('tm')
library(tm)
doc <- Corpus(VectorSource(words))
tdm <- TermDocumentMatrix(doc)
inspect(tdm)
tdm <- TermDocumentMatrix(words)
synonym_list <- vector('list', length=length(keywords))
length(keywords)
output <- vector('list', length=length(keywords))
length(output)
rm(list=ls())
# 엑셀파일 로딩
news_df <- readxl::read_excel('NewsResult.xlsx',sheet = 1)
# 데이터 프레임을 벡터로 변환한다.
news_vec <- news_df %>% select('키워드') %>% unlist(use.names = F)
# 키워드를 담을 list 생성
keywords <- vector('list', length=length(news_vec))
for( i in keywords){
print('1')
}
for( i in keywords){
print(i)
}
# , 단위 분리
for ( i in 1:length(keywords)){
keywords[[i]] <- str_split(news_vec[i],',', simplify = T)}
keywords[[1]]
keywords[[1]][1]
keywords[[2]][1]
keywords[[3]][1]
keywords[[2485]][1]
# 키워드를 담을 list 생성
keywords <- vector('list', length=length(news_vec))
# , 단위 분리 & 중복 단어 제거
for ( i in 1:length(keywords)){
keywords[[i]] <- str_split(news_vec[i],',', simplify = T)
keywords[[i]] <- unique(keywords[[i]]) }
word_count <- unlist(keywords)
length(word_count)
# , 단위 분리 & 중복 단어 제거
for ( i in 1:length(keywords)){
keywords[[i]] <- unique(str_split(news_vec[i],',', simplify = T)) }
word_count <- unlist(keywords)
length(word_count)
# 키워드를 담을 list 생성
keywords <- vector('list', length=length(news_vec))
# , 단위 분리 & 중복 단어 제거
for ( i in 1:length(keywords)){
keywords[[i]] <- unique(str_split(news_vec[i],',', simplify = T)) }
word_count <- unlist(keywords)
length(word_count)
length(words)
# 키워드를 담을 list 생성
keywords <- vector('list', length=length(news_vec))
# , 단위 분리 & 중복 단어 제거
for ( i in 1:length(keywords)){
keywords[[i]] <- unique(str_split(news_vec[i],',', simplify = F)) }
word_count <- unlist(keywords)
length(word_count)
# 키워드를 담을 list 생성
keywords <- vector('list', length=length(news_vec))
# , 단위 분리 & 중복 단어 제거
for ( i in 1:length(keywords)){
keywords[[i]] <- str_split(news_vec[i],',', simplify = F) }
word_count <- unlist(keywords)
length(word_count)
for ( i in 1:length(keywords)){
keywords[[i]] <- unique(keywords[[i]]) }
word_count <- unlist(keywords)
length(word_count)
keywords[[1]]
length(keywords[[1]])
keywords[[1]][1]
keywords[[1]][1][1]
str(keywords0
str(keywords)
str(keywords)
# 키워드를 담을 list 생성
keywords <- vector('list', length=length(news_vec))
# , 단위 분리 & 중복 단어 제거
for ( i in 1:length(keywords)){
keywords[[i]] <- str_split(news_vec[i],',', simplify = T) }
str(keywords)
length(keywords[[1]])
length(keywords[[1]])
keywords[[1]] <- unique(keywords[[1]])
length(keywords[[1]])
length(keywords[[2]])
keywords[[2]] <- unique(keywords[[2]])
length(keywords[[2]])
??unique
a <- c('a','a','a')
unique(a)
keywords[[2]]
str(keywords[[2]])
class(keywords[[2]])
class(keywords[[1]])
class(keywords)
a <- str_split(news_vec[1],',', simplify = T)
class(a)
a <- str_split(news_vec[1],',', simplify = F)
class(a)
a <- str_split(news_vec[1],',', simplify = F)
class(a)
a
class(a)
a <- str_split(news_vec[1],',', simplify = T)
class(a)
# 키워드를 담을 list 생성
keywords <- vector('list', length=length(news_vec))
# , 단위 분리 & 중복 단어 제거
for ( i in 1:length(keywords)){
keywords[[i]] <- unlist(str_split(news_vec[i],','))}
for ( i in 1:length(keywords)){
keywords[[i]] <- unique(keywords[[i]]) }
word_count <- unlist(keywords)
length(word_count)
# 키워드를 담을 list 생성
keywords <- vector('list', length=length(news_vec))
# , 단위 분리 & 중복 단어 제거
for ( i in 1:length(keywords)){
keywords[[i]] <- unique(unlist(str_split(news_vec[i],',')))}
word_count <- unlist(keywords)
length(word_count)
# 키워드를 담을 list 생성
keywords <- vector('list', length=length(news_vec))
# , 단위 분리 & 중복 단어 제거
for ( i in 1:length(keywords)){
words <- unlist(str_split(news_vec[i],','))
keywords[[i]] <- unique(words)}
word_count <- unlist(keywords)
length(word_count)
# 키워드를 담을 list 생성
keywords <- vector('list', length=length(news_vec))
# , 단위 분리 & 중복 단어 제거
for ( i in 1:length(keywords)){
words <- str_split(news_vec[i],',')
keywords[[i]] <- unique(words)}
word_count <- unlist(keywords)
length(word_count)
# 키워드를 담을 list 생성
keywords <- vector('list', length=length(news_vec))
# , 단위 분리 & 중복 단어 제거
for ( i in 1:length(keywords)){
words <- unlist(str_split(news_vec[i],','))
keywords[[i]] <- unique(words)}
word_count <- table(unlist(keywords))
length(word_count)
# 키워드를 담을 list 생성
keywords <- vector('list', length=length(news_vec))
# , 단위 분리 & 중복 단어 제거
for ( i in 1:length(keywords)){
words <- unlist(str_split(news_vec[i],','))
keywords[[i]] <- unique(words)}
word_count <- table(unlist(keywords))
head(word_count)
View(word_count)
word_count <- str_sort(word_count,decreasing = T)
View(word_count)
word_count <- table(unlist(keywords))
word_count <- sort(word_count,decreasing = T)
View(word_count)
word_count <- table(unlist(keywords))
word_count %>% arrange('Freq')
as_tibble(word_count) %>% arrange(desc(Freq))
as_tibble(word_count) %>% arrange(desc('Freq'))
as_tibble(word_count) %>% arrange(desc(Freq))
as_tibble(word_count)
as_tibble(word_count) %>% rename(word=Var1, freq=n)
word_count2 <- as_tibble(word_count) %>% rename(word=Var1, freq=n) %>% arrange(desc(freq))
word_count
word_count2
tibble(word=word_count$Var1, freq2=word_count$Freq)
str(word_count)
word_count[50,]
word_count[50]
word_count[1]
word_count
word_count <- as_tibble(word_count) %>% rename(word=Var1, freq=n) %>% arrange(desc(freq))
word_count
word_count[50,]
word_count[1:50,]
top_50 <- word_count[2:51,]
wordcloud2(top_50)
wordcloud2(top_50, size=0.5)
wordcloud2(top_50, color='random-dark')
wordcloud2(top_50, color='random-light', backgroundColor = 'black')
wordcloud2(top_50, size=0.5, color='random-light', backgroundColor = 'gray')
wordcloud2(top_50, size=0.5, color='random-light', backgroundColor = 'darkgray')
wordcloud2(top_50, size=0.5, color='random-light', backgroundColor = 'black')
wordcloud2(top_50, size=0.5, color='random-light', backgroundColor = 'black')
wordcloud2(top_50,figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(top_50, size=0.5, figPath = 'korea.png', fontFamily = 'Spoqa Han Sans')
top_50
class(top_50)
wordcloud2(top_50, size=0.5, figPath = 'korea.png', fontFamily = 'Spoqa Han Sans')
wordcloud2(top_50, size=0.5, figPath = 'korea.png', fontFamily = 'SpoqaHanSans')
wordcloud2(top_50, size=0.5, figPath = 'korea.png', fontFamily = 'D2Coding')
wordcloud2(top_50, size=0.5, color='random-light', figPath = 'korea.png', fontFamily = 'D2Coding', backgroundColor = 'black')
# 키워드를 담을 list 생성
keywords <- vector('list', length=length(news_vec))
# , 단위 분리 & 중복 단어 제거
for ( i in 1:length(keywords)){
words <- unlist(str_split(news_vec[i],','))
keywords[[i]] <- unique(words)}
length(unlist(keywords))
word_count
word_count[word_count$word=='청년']
word_count[word_count$word=='청년',]
word_count[word_count$word=='실업',]
# 단어 정리
word_count[word_count$word %in% c('청년','실업') ]
# 단어 정리
word_count[word_count$word %in% c('청년','실업'),]
# 단어 정리
word_count[!word_count$word %in% c('청년','실업'),]
# 단어 정리
word_count[!(word_count$word %in% c('청년','실업')),]
# 단어 정리
condition <- !(word_count$word %in% c('청년','실업'))
word_count[condition,]
word_count[rm_condition,]
# 단어 정리
rm_condition <- !(word_count$word %in% c('청년','실업'))
word_count[rm_condition,]
# 단어 정리
rm_condition <- !(word_count$word %in% c('청년','실업'))
word_count <- word_count[rm_condition,]
top_50 <- word_count[1:50,]
# 단어 정리
rm_cond <- !(word_count$word %in% c('청년','실업'))
word_count <- word_count[rm_cond,]
library(wordcloud2)
top_50 <- word_count[1:50,]
wordcloud2(top_50, size=0.5, color='random-light', backgroundColor = 'black')
# 불필요한 단어 정리
rm_cond <- !(word_count$word %in% c('청년실업','청년','실업'))
word_count <- word_count[rm_cond,]
word_count
word_count
# 키워드를 담을 list 생성
keywords <- vector('list', length=length(news_vec))
# , 단위 분리 & 중복 단어 제거
for ( i in 1:length(keywords)){
words <- unlist(str_split(news_vec[i],','))
keywords[[i]] <- unique(words)}
# 단어 별 카운트 후 정렬
word_count <- table(unlist(keywords))
word_count <- as_tibble(word_count) %>% rename(word=Var1, freq=n) %>% arrange(desc(freq))
word_count
# 불필요한 단어 정리
rm_cond <- !(word_count$word %in% c('청년실업','청년','실업'))
word_count <- word_count[rm_cond,]
library(wordcloud2)
top_50 <- word_count[1:50,]
wordcloud2(top_50, size=0.5, color='random-light', backgroundColor = 'black')
# 지도 이미지 워드클라우드
wordcloud2(top_50, size=0.5, color='random-light', figPath = 'korea.png', fontFamily = 'D2Coding', backgroundColor = 'black')
keywords[1]
news_vec[1]
news_vec[1][1:50]
news_vec[1]
txt <- "도시가스,기자재,분야,검토"
str_split(txt, ',')
txt <- "도시가스,기자재,분야,검토"
str_split(txt, ',', simplify = F)
rm(list=ls())
txt <- "도시가스,기자재,분야,검토"
str_split(txt, ',', simplify = F)
str_split(txt, ',', simplify = T)
str_split_fixed(txt, ',', 2)
class(str_split_fixed(txt, ',', 2))
